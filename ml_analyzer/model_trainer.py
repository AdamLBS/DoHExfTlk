#!/usr/bin/env python3
"""
Entra√Æneur de mod√®les ML pour la d√©tection d'exfiltration DoH
Adapt√© pour les datasets de flow r√©seau avec features statistiques
"""

import os
import json
import logging
import argparse
import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, StratifiedKFold
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, accuracy_score
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.utils import resample
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import RandomUnderSampler
from imblearn.combine import SMOTEENN
import joblib
import warnings
warnings.filterwarnings('ignore')

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class NetworkFlowMLTrainer:
    """Entra√Æneur ML pour datasets de flow r√©seau"""
    
    def __init__(self, quick_mode=False):
        self.quick_mode = quick_mode
        self.max_samples = 2000 if quick_mode else None
        self.setup_directories()
        self.scaler = StandardScaler()
        self.label_encoder = LabelEncoder()
        self.smote = SMOTE(random_state=42)
        self.use_class_balancing = True
        self.cross_val_folds = 3 if quick_mode else 5  # R√©duire les folds en mode quick
        
        # Features num√©riques du dataset r√©seau
        self.numeric_features = [
            'SourcePort', 'DestinationPort', 'Duration', 
            'FlowBytesSent', 'FlowSentRate', 'FlowBytesReceived', 'FlowReceivedRate',
            'PacketLengthVariance', 'PacketLengthStandardDeviation', 'PacketLengthMean',
            'PacketLengthMedian', 'PacketLengthMode', 'PacketLengthSkewFromMedian',
            'PacketLengthSkewFromMode', 'PacketLengthCoefficientofVariation',
            'PacketTimeVariance', 'PacketTimeStandardDeviation', 'PacketTimeMean',
            'PacketTimeMedian', 'PacketTimeMode', 'PacketTimeSkewFromMedian',
            'PacketTimeSkewFromMode', 'PacketTimeCoefficientofVariation',
            'ResponseTimeTimeVariance', 'ResponseTimeTimeStandardDeviation',
            'ResponseTimeTimeMean', 'ResponseTimeTimeMedian', 'ResponseTimeTimeMode',
            'ResponseTimeTimeSkewFromMedian', 'ResponseTimeTimeSkewFromMode',
            'ResponseTimeTimeCoefficientofVariation'
        ]
        
        # Configuration des mod√®les avec r√©gularisation anti-overfitting
        if quick_mode:
            # Configuration simplifi√©e pour mode quick
            self.models_config = {
                'random_forest': {
                    'model': RandomForestClassifier,
                    'params': {
                        'n_estimators': [50, 100],
                        'max_depth': [10, 15],
                        'min_samples_split': [10],
                        'min_samples_leaf': [5],
                        'max_features': ['sqrt'],
                        'class_weight': ['balanced'] if self.use_class_balancing else [None],
                        'random_state': [42]
                    }
                },
                'logistic_regression': {
                    'model': LogisticRegression,
                    'params': {
                        'C': [0.1, 1],
                        'penalty': ['l2'],
                        'class_weight': ['balanced'] if self.use_class_balancing else [None],
                        'random_state': [42],
                        'max_iter': [1000]
                    }
                }
            }
        else:
            # Configuration compl√®te pour mode normal
            self.models_config = {
                'random_forest': {
                    'model': RandomForestClassifier,
                    'params': {
                        'n_estimators': [100, 200],
                        'max_depth': [10, 15, 20],  # Limiter la profondeur
                        'min_samples_split': [5, 10, 20],  # Augmenter min_samples_split
                        'min_samples_leaf': [2, 5, 10],   # Ajouter min_samples_leaf
                        'max_features': ['sqrt', 'log2', 0.8],  # Limiter les features
                        'class_weight': ['balanced'] if self.use_class_balancing else [None],
                        'random_state': [42]
                    }
                },
                'gradient_boosting': {
                    'model': GradientBoostingClassifier,
                    'params': {
                        'n_estimators': [100, 150],  # R√©duire pour √©viter l'overfitting
                        'learning_rate': [0.05, 0.1, 0.15],  # Ajouter des taux plus faibles
                        'max_depth': [3, 5],  # Limiter la profondeur
                        'min_samples_split': [10, 20],  # Augmenter
                        'min_samples_leaf': [5, 10],   # Ajouter
                        'subsample': [0.8, 0.9],  # Sous-√©chantillonnage
                        'random_state': [42]
                    }
                },
                'logistic_regression': {
                    'model': LogisticRegression,
                    'params': {
                        'C': [0.01, 0.1, 1],  # Ajouter plus de r√©gularisation
                        'penalty': ['l1', 'l2', 'elasticnet'],  # Diff√©rents types de r√©gularisation
                        'l1_ratio': [0.5],  # Pour elasticnet
                        'solver': ['liblinear', 'saga'],  # Saga pour elasticnet
                        'class_weight': ['balanced'] if self.use_class_balancing else [None],
                        'random_state': [42],
                        'max_iter': [1000, 2000]
                    }
                },
                'svm': {
                    'model': SVC,
                    'params': {
                        'C': [0.1, 1, 5],  # R√©duire C pour plus de r√©gularisation
                        'kernel': ['rbf', 'linear'],
                        'gamma': ['scale', 'auto', 0.1, 0.01],  # Contr√¥ler la complexit√©
                        'class_weight': ['balanced'] if self.use_class_balancing else [None],
                        'probability': [True],
                        'random_state': [42]
                    }
                }
            }
    
    def setup_directories(self):
        """Cr√©e les r√©pertoires n√©cessaires"""
        self.models_dir = Path("../models") #TODO : Adapt to current directory
        self.reports_dir = Path("../ml_reports")
        
        self.models_dir.mkdir(exist_ok=True)
        self.reports_dir.mkdir(exist_ok=True)
        
        logger.info(f"üìÅ R√©pertoires cr√©√©s: {self.models_dir}, {self.reports_dir}")
    
    def load_datasets(self):
        """Charge tous les datasets disponibles"""
        logger.info("üìä Chargement des datasets...")
        
        datasets_dir = Path("../datasets")
        all_data = []
        
        # Chercher tous les fichiers CSV dans le dossier datasets
        if datasets_dir.exists():
            csv_files = list(datasets_dir.glob("*.csv"))
            logger.info(f"ÔøΩÔøΩ Fichiers CSV trouv√©s: {[f.name for f in csv_files]}")
            
            for csv_file in csv_files:
                try:
                    logger.info(f"üìà Chargement: {csv_file.name}")
                    df = pd.read_csv(csv_file)
                    
                    # V√©rifier que le fichier a la colonne Label
                    if 'Label' in df.columns:
                        logger.info(f"‚úÖ {csv_file.name}: {len(df)} lignes, Labels: {df['Label'].value_counts().to_dict()}")
                        all_data.append(df)
                    else:
                        logger.warning(f"‚ö†Ô∏è {csv_file.name}: Pas de colonne 'Label', ignor√©")
                        
                except Exception as e:
                    logger.error(f"‚ùå Erreur chargement {csv_file.name}: {e}")
        
        if all_data:
            combined_df = pd.concat(all_data, ignore_index=True)
            logger.info(f"üìä Dataset combin√©: {len(combined_df)} lignes")
            logger.info(f"üìä Distribution des labels: {combined_df['Label'].value_counts().to_dict()}")
            
            # Appliquer la limitation en mode quick
            if self.quick_mode and self.max_samples and len(combined_df) > self.max_samples:
                logger.info(f"üöÄ Mode quick activ√©: limitation √† {self.max_samples} √©chantillons")
                # √âchantillonnage stratifi√© pour conserver la distribution des classes
                combined_df = combined_df.groupby('Label').apply(
                    lambda x: x.sample(min(len(x), self.max_samples // combined_df['Label'].nunique()), 
                                     random_state=42)
                ).reset_index(drop=True)
                logger.info(f"üìä Dataset limit√©: {len(combined_df)} lignes")
                logger.info(f"üìä Nouvelle distribution: {combined_df['Label'].value_counts().to_dict()}")
            
            return combined_df
        else:
            logger.error("‚ùå Aucun dataset valide trouv√©")
            return None
    
    def preprocess_data(self, df):
        """Pr√©processe les donn√©es"""
        logger.info("üîÑ Pr√©processing des donn√©es...")
        
        df_processed = df.copy()
        
        # S√©lectionner seulement les features num√©riques disponibles
        available_numeric_features = [col for col in self.numeric_features if col in df_processed.columns]
        logger.info(f"üìä Features num√©riques disponibles: {len(available_numeric_features)}/{len(self.numeric_features)}")
        
        # V√©rifier les valeurs manquantes
        missing_info = df_processed[available_numeric_features].isnull().sum()
        if missing_info.sum() > 0:
            logger.warning(f"‚ö†Ô∏è Valeurs manquantes d√©tect√©es:")
            for col, missing in missing_info[missing_info > 0].items():
                logger.warning(f"  - {col}: {missing} valeurs manquantes")
        
        # Remplacer les valeurs manquantes par la m√©diane
        for col in available_numeric_features:
            if df_processed[col].isnull().sum() > 0:
                median_val = df_processed[col].median()
                df_processed[col].fillna(median_val, inplace=True)
        
        # Remplacer les valeurs infinies
        df_processed = df_processed.replace([np.inf, -np.inf], np.nan)
        for col in available_numeric_features:
            if df_processed[col].isnull().sum() > 0:
                median_val = df_processed[col].median()
                df_processed[col].fillna(median_val, inplace=True)
        
        # Pr√©parer les features et le target
        X = df_processed[available_numeric_features]
        y = df_processed['Label']
        
        # Encoder les labels (Benign = 0, Malicious = 1)
        y_encoded = self.label_encoder.fit_transform(y)
        
        # Normaliser les features
        X_scaled = self.scaler.fit_transform(X)
        X_scaled = pd.DataFrame(X_scaled, columns=available_numeric_features)
        
        logger.info(f"‚úÖ Preprocessing termin√©: {X_scaled.shape[0]} √©chantillons, {X_scaled.shape[1]} features")
        logger.info(f"üìä Classes encod√©es: {dict(zip(self.label_encoder.classes_, range(len(self.label_encoder.classes_))))}")
        
        return X_scaled, y_encoded, available_numeric_features
    
    def balance_dataset(self, X, y, method='smote'):
        """√âquilibre le dataset pour r√©duire le biais de classe"""
        logger.info(f"‚öñÔ∏è √âquilibrage du dataset avec {method}...")
        
        # Distribution originale
        unique, counts = np.unique(y, return_counts=True)
        logger.info(f"üìä Distribution avant: {dict(zip(self.label_encoder.classes_[unique], counts))}")
        
        try:
            if method == 'smote':
                # SMOTE pour g√©n√©rer des √©chantillons synth√©tiques de la classe minoritaire
                X_balanced, y_balanced = self.smote.fit_resample(X, y)
                
            elif method == 'undersample':
                # Sous-√©chantillonnage de la classe majoritaire
                undersampler = RandomUnderSampler(random_state=42, sampling_strategy=0.5)  # 2:1 ratio
                X_balanced, y_balanced = undersampler.fit_resample(X, y)
                
            elif method == 'combined':
                # Combinaison SMOTE + sous-√©chantillonnage
                smote_enn = SMOTEENN(random_state=42)
                X_balanced, y_balanced = smote_enn.fit_resample(X, y)
                
            else:
                logger.warning(f"‚ö†Ô∏è M√©thode {method} inconnue, pas d'√©quilibrage")
                return X, y
            
            # Distribution apr√®s √©quilibrage
            unique_after, counts_after = np.unique(y_balanced, return_counts=True)
            logger.info(f"üìä Distribution apr√®s: {dict(zip(self.label_encoder.classes_[unique_after], counts_after))}")
            logger.info(f"‚úÖ √âquilibrage termin√©: {len(X)} ‚Üí {len(X_balanced)} √©chantillons")
            
            return X_balanced, y_balanced
            
        except Exception as e:
            logger.error(f"‚ùå Erreur √©quilibrage: {e}")
            return X, y
    
    def train_model(self, model_name, model_config, X_train, y_train, X_val, y_val):
        """Entra√Æne un mod√®le avec optimisation des hyperparam√®tres et validation robuste"""
        logger.info(f"ü§ñ Entra√Ænement {model_name}...")
        
        try:
            # Cross-validation stratifi√©e pour g√©rer le d√©s√©quilibre
            stratified_cv = StratifiedKFold(n_splits=self.cross_val_folds, shuffle=True, random_state=42)
            
            # Grid Search avec validation stratifi√©e
            grid_search = GridSearchCV(
                model_config['model'](),
                model_config['params'],
                cv=stratified_cv,
                scoring='roc_auc',  # Meilleure m√©trique pour donn√©es d√©s√©quilibr√©es
                n_jobs=-1,
                verbose=2,
                return_train_score=True  # Pour d√©tecter l'overfitting
            )
            
            grid_search.fit(X_train, y_train)
            best_model = grid_search.best_estimator_
            
            # Analyser l'overfitting avec train vs validation scores
            train_scores = grid_search.cv_results_['mean_train_score']
            val_scores = grid_search.cv_results_['mean_test_score']
            best_idx = grid_search.best_index_
            
            train_score_best = train_scores[best_idx]
            val_score_best = val_scores[best_idx]
            overfitting_gap = train_score_best - val_score_best
            
            # Pr√©dictions sur validation
            val_pred = best_model.predict(X_val)
            val_proba = best_model.predict_proba(X_val)[:, 1]
            
            # M√©triques
            val_accuracy = accuracy_score(y_val, val_pred)
            val_auc = roc_auc_score(y_val, val_proba)
            
            # Cross-validation finale
            cv_scores = cross_val_score(best_model, X_train, y_train, 
                                      cv=stratified_cv, scoring='roc_auc')
            
            results = {
                'model': best_model,
                'best_params': grid_search.best_params_,
                'val_accuracy': val_accuracy,
                'val_auc': val_auc,
                'cv_mean': cv_scores.mean(),
                'cv_std': cv_scores.std(),
                'train_score': train_score_best,
                'val_score': val_score_best,
                'overfitting_gap': overfitting_gap,
                'classification_report': classification_report(y_val, val_pred, 
                                                             target_names=self.label_encoder.classes_)
            }
            
            # Alertes overfitting
            if overfitting_gap > 0.05:
                logger.warning(f"‚ö†Ô∏è {model_name}: Possible overfitting d√©tect√© (gap: {overfitting_gap:.3f})")
            
            logger.info(f"‚úÖ {model_name}: Accuracy={val_accuracy:.3f}, AUC={val_auc:.3f}, "
                       f"CV={cv_scores.mean():.3f}(¬±{cv_scores.std():.3f}), Gap={overfitting_gap:.3f}")
            
            return results
            
        except Exception as e:
            logger.error(f"‚ùå Erreur {model_name}: {e}")
            return None
    
    def train_all_models(self):
        """Entra√Æne tous les mod√®les"""
        logger.info("üöÄ D√©but de l'entra√Ænement...")
        
        # Charger les donn√©es
        df = self.load_datasets()
        if df is None:
            return {}
        
        # Pr√©processing
        X, y, feature_names = self.preprocess_data(df)
        
        # Division train/validation/test (test d'abord pour garder l'√©quilibre original)
        X_temp, X_test, y_temp, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )
        X_train, X_val, y_train, y_val = train_test_split(
            X_temp, y_temp, test_size=0.25, random_state=42, stratify=y_temp
        )
        
        # √âquilibrage seulement sur les donn√©es d'entra√Ænement
        if self.use_class_balancing:
            logger.info("‚öñÔ∏è Application de l'√©quilibrage des classes...")
            X_train_balanced, y_train_balanced = self.balance_dataset(X_train, y_train, method='smote')
        else:
            X_train_balanced, y_train_balanced = X_train, y_train
        
        logger.info(f"üìä Division: Train={len(X_train_balanced)}, Val={len(X_val)}, Test={len(X_test)}")
        
        # Entra√Æner tous les mod√®les
        trained_models = {}
        best_model = None
        best_auc = 0
        
        for model_name, model_config in self.models_config.items():
            result = self.train_model(model_name, model_config, X_train_balanced, y_train_balanced, X_val, y_val)
            
            if result:
                trained_models[model_name] = result
                
                # Test final
                test_pred = result['model'].predict(X_test)
                test_proba = result['model'].predict_proba(X_test)[:, 1]
                test_accuracy = accuracy_score(y_test, test_pred)
                test_auc = roc_auc_score(y_test, test_proba)
                
                logger.info(f"üèÜ {model_name} Test: Accuracy={test_accuracy:.3f}, AUC={test_auc:.3f}")
                
                # Garder le meilleur mod√®le
                if test_auc > best_auc:
                    best_auc = test_auc
                    best_model = (model_name, result['model'])
                
                # Sauvegarder le mod√®le
                model_path = self.models_dir / f"{model_name}.pkl"
                joblib.dump(result['model'], model_path)
                logger.info(f"üíæ Mod√®le sauvegard√©: {model_path}")
                
                # Rapport d√©taill√©
                self.save_model_report(model_name, result, test_accuracy, test_auc, 
                                     X_test, y_test, test_pred, len(X_train_balanced))
        
        # Sauvegarder les pr√©processeurs
        preprocessors = {
            'scaler': self.scaler,
            'label_encoder': self.label_encoder,
            'feature_names': feature_names
        }
        joblib.dump(preprocessors, self.models_dir / "preprocessors.pkl")
        
        if best_model:
            logger.info(f"üèÜ Meilleur mod√®le: {best_model[0]} (AUC Test: {best_auc:.3f})")
            # Sauvegarder le meilleur mod√®le s√©par√©ment
            joblib.dump(best_model[1], self.models_dir / "best_model.pkl")
        
        logger.info("‚úÖ Entra√Ænement termin√©!")
        return trained_models
    
    def save_model_report(self, model_name, results, test_acc, test_auc, X_test, y_test, test_pred, train_size):
        """Sauvegarde un rapport d√©taill√© avec analyse d'overfitting"""
        report_path = self.reports_dir / f"{model_name}_report.txt"
        
        # Analyse overfitting
        overfitting_status = "üü¢ Pas d'overfitting d√©tect√©"
        if results['overfitting_gap'] > 0.1:
            overfitting_status = "üî¥ Overfitting s√©v√®re d√©tect√©"
        elif results['overfitting_gap'] > 0.05:
            overfitting_status = "üü° Overfitting mod√©r√© d√©tect√©"
        
        report_content = f"""
=== Rapport d'entra√Ænement: {model_name} ===
Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

Hyperparam√®tres optimaux:
{json.dumps(results['best_params'], indent=2)}

Analyse de l'overfitting:
{overfitting_status}
- Score train CV: {results['train_score']:.4f}
- Score validation CV: {results['val_score']:.4f}
- √âcart (Gap): {results['overfitting_gap']:.4f}

Performance Validation:
- Accuracy: {results['val_accuracy']:.4f}
- AUC-ROC: {results['val_auc']:.4f}
- Cross-Validation: {results['cv_mean']:.4f} (¬±{results['cv_std']:.4f})

Performance Test:
- Accuracy: {test_acc:.4f}
- AUC-ROC: {test_auc:.4f}

Informations dataset:
- √âchantillons entra√Ænement: {train_size}
- √âchantillons validation: {len(X_test)}
- √âchantillons test: {len(X_test)}

Classification Report (Validation):
{results['classification_report']}

Matrice de confusion (Test):
{confusion_matrix(y_test, test_pred)}

Features utilis√©es: {X_test.shape[1]}
Classes: {list(self.label_encoder.classes_)}

Recommandations anti-overfitting:
- ‚úì Cross-validation stratifi√©e utilis√©e
- ‚úì R√©gularisation appliqu√©e
- ‚úì √âquilibrage des classes appliqu√©
- ‚úì Division train/val/test stratifi√©e
- ‚úì Hyperparam√®tres optimis√©s pour la g√©n√©ralisation
"""
        
        with open(report_path, 'w') as f:
            f.write(report_content)
    
    def predict_new_data(self, model_name, new_data_df):
        """Fait des pr√©dictions sur de nouvelles donn√©es (sans label)"""
        try:
            # Charger le mod√®le et pr√©processeurs
            model_path = self.models_dir / f"{model_name}.pkl"
            preprocessors_path = self.models_dir / "preprocessors.pkl"
            
            if not model_path.exists() or not preprocessors_path.exists():
                logger.error("‚ùå Mod√®le ou pr√©processeurs introuvables")
                return None
            
            model = joblib.load(model_path)
            preprocessors = joblib.load(preprocessors_path)
            
            # Pr√©processing des nouvelles donn√©es
            feature_names = preprocessors['feature_names']
            available_features = [col for col in feature_names if col in new_data_df.columns]
            
            X_new = new_data_df[available_features]
            
            # Remplacer valeurs manquantes et infinies
            for col in available_features:
                median_val = X_new[col].median()
                X_new[col] = X_new[col].replace([np.inf, -np.inf], np.nan).fillna(median_val)
            
            # Normaliser
            X_scaled = preprocessors['scaler'].transform(X_new)
            
            # Pr√©dictions
            predictions = model.predict(X_scaled)
            probabilities = model.predict_proba(X_scaled)
            
            # Convertir les pr√©dictions en labels
            predicted_labels = preprocessors['label_encoder'].inverse_transform(predictions)
            
            return {
                'predictions': predicted_labels,
                'probabilities': probabilities,
                'confidence': np.max(probabilities, axis=1)
            }
            
        except Exception as e:
            logger.error(f"‚ùå Erreur pr√©diction: {e}")
            return None

def main():
    """Point d'entr√©e principal"""
    parser = argparse.ArgumentParser(description='Entra√Æneur ML pour datasets de flow r√©seau')
    parser.add_argument('--quick', action='store_true', 
                       help='Mode quick: limite le dataset √† 2000 √©chantillons pour un entra√Ænement rapide')
    
    args = parser.parse_args()
    
    if args.quick:
        logger.info("üöÄ Mode QUICK activ√© - Entra√Ænement rapide avec 2000 √©chantillons max")
    
    trainer = NetworkFlowMLTrainer(quick_mode=args.quick)
    
    try:
        models = trainer.train_all_models()
        logger.info(f"üéâ Entra√Ænement termin√©! {len(models)} mod√®les cr√©√©s.")
        
        if args.quick:
            logger.info("‚úÖ Mode quick termin√© - Pour un entra√Ænement complet, lancez sans --quick")
        
        # Test rapide de pr√©diction
        logger.info("üß™ Test de pr√©diction...")
        
        # Charger un √©chantillon pour tester
        datasets_dir = Path("../datasets")
        test_file = next(datasets_dir.glob("*.csv"), None)
        
        if test_file:
            sample_df = pd.read_csv(test_file).head(5)
            # Retirer la colonne Label pour simuler de nouvelles donn√©es
            sample_df_no_label = sample_df.drop('Label', axis=1)
            
            # Tester avec le meilleur mod√®le s'il existe
            if (trainer.models_dir / "best_model.pkl").exists():
                # Utiliser n'importe quel mod√®le pour le test
                model_files = list(trainer.models_dir.glob("*.pkl"))
                if model_files:
                    model_name = model_files[0].stem
                    if model_name != "preprocessors" and model_name != "best_model":
                        predictions = trainer.predict_new_data(model_name, sample_df_no_label)
                        if predictions:
                            logger.info(f"‚úÖ Test pr√©dictions: {predictions['predictions']}")
        
    except Exception as e:
        logger.error(f"‚ùå Erreur fatale: {e}")

if __name__ == "__main__":
    main()
